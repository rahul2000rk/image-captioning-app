import gradio as gr
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer
from PIL import Image
import torch
import time
import os

# Load model and processor
model_name = "nlpconnect/vit-gpt2-image-captioning"
model = VisionEncoderDecoderModel.from_pretrained(model_name)
processor = ViTImageProcessor.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a captions directory if it doesn't exist
os.makedirs("captions", exist_ok=True)

# Inference and saving function
def generate_caption_and_save(image):
    if image is None:
        return None, "No image provided."

    # Preprocess
    pixel_values = processor(images=image, return_tensors="pt").pixel_values.to(device)

    # Generate caption
    output_ids = model.generate(pixel_values, max_length=16, num_beams=4)
    caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)

    # Save to file with timestamp
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    filename = f"captions/caption_{timestamp}.txt"
    with open(filename, "w") as f:
        f.write(caption)

    return image, f"üì∏ Caption: {caption}\nüíæ Saved to `{filename}`"

# Gradio interface
with gr.Blocks(title="Image Captioning App") as demo:
    gr.Markdown("# üñºÔ∏è Image Captioning with Hugging Face")
    gr.Markdown("Upload or paste an image and get a caption generated by ViT-GPT2. Captions are also saved to a local file.")

    with gr.Row():
        with gr.Column():
            image_input = gr.Image(type="pil", label="Upload or Paste Image")
            generate_btn = gr.Button("Generate Caption")
            clear_btn = gr.Button("Clear")
        with gr.Column():
            image_output = gr.Image(label="Image Preview")
            caption_output = gr.Textbox(label="Generated Caption", lines=4)

    generate_btn.click(fn=generate_caption_and_save, inputs=image_input, outputs=[image_output, caption_output])
    clear_btn.click(fn=lambda: (None, ""), inputs=[], outputs=[image_output, caption_output])

demo.launch()
